{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the Morse code audio files\n",
    "DATA_PATH = './morse_code_train_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract MFCC features from an audio file\n",
    "def extract_features(file_path):\n",
    "    audio, sample_rate = librosa.load(file_path)\n",
    "    # Extract 40 MFCC features\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "    # Take the mean of the MFCCs over time to reduce the feature dimensionality\n",
    "    mfccs_mean = np.mean(mfccs.T, axis=0)\n",
    "    return mfccs_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset and extract features\n",
    "def load_data():\n",
    "    features = []  # To store MFCC features\n",
    "    labels = []    # To store the corresponding labels (letters/numbers)\n",
    "    \n",
    "    # Loop through all files in the data directory\n",
    "    for file_name in os.listdir(DATA_PATH):\n",
    "        if file_name.endswith('.wav'):\n",
    "            # Extract the label from the file name (e.g., 'A.wav' -> label 'A')\n",
    "            label = file_name[0]  # Assuming the first character of the filename is the label\n",
    "            file_path = os.path.join(DATA_PATH, file_name)\n",
    "            \n",
    "            # Extract features from the audio file\n",
    "            mfccs = extract_features(file_path)\n",
    "            \n",
    "            # Append the features and label to their respective lists\n",
    "            features.append(mfccs)\n",
    "            labels.append(label)\n",
    "    \n",
    "    return np.array(features), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (36, 40), Labels shape: (36,)\n"
     ]
    }
   ],
   "source": [
    "# Call the load_data function to get the features and labels\n",
    "X, y = load_data()\n",
    "\n",
    "# Print shapes of X and y to confirm\n",
    "print(f\"Features shape: {X.shape}, Labels shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features shape: (36, 40), Training Labels shape: (36,)\n",
      "Testing Features shape: (9, 40), Testing Labels shape: (9,)\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Path to the Morse code audio files\n",
    "DATA_PATH = './morse_code_train_data/'\n",
    "\n",
    "# Function to extract MFCC features from an audio file\n",
    "def extract_features(file_path):\n",
    "    audio, sample_rate = librosa.load(file_path)\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "    return np.mean(mfccs.T, axis=0)\n",
    "\n",
    "# Load the dataset and extract features\n",
    "def load_data():\n",
    "    features = []  # To store MFCC features\n",
    "    labels = []    # To store the corresponding labels (letters/numbers)\n",
    "    \n",
    "    # Loop through all files in the data directory\n",
    "    for file_name in os.listdir(DATA_PATH):\n",
    "        if file_name.endswith('.wav'):\n",
    "            label = file_name[0]  # Assuming the first character of the filename is the label\n",
    "            file_path = os.path.join(DATA_PATH, file_name)\n",
    "            mfccs = extract_features(file_path)\n",
    "            features.append(mfccs)\n",
    "            labels.append(label)\n",
    "    \n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "# Load the full dataset\n",
    "X, y = load_data()\n",
    "\n",
    "# Manually specify which files to include in the testing set\n",
    "# Example: Let's say we want to test on these letters\n",
    "testing_files = ['A.wav', 'B.wav', 'C.wav', 'Z.wav', 'Y.wav', 'X.wav', '1.wav', '0.wav', 'H.wav']  # Add any letters you want to test\n",
    "\n",
    "# Initialize lists for training and testing data\n",
    "X_train, y_train = [], []\n",
    "X_test, y_test = [], []\n",
    "\n",
    "# Split the data\n",
    "for file_name in os.listdir(DATA_PATH):\n",
    "    if file_name.endswith('.wav'):\n",
    "        # If the file is in the testing set, add to test data\n",
    "        if file_name in testing_files:\n",
    "            index = np.where(y == file_name[0])[0][0]  # Get index of the label in original labels\n",
    "            X_test.append(X[index])  # Add corresponding features to test set\n",
    "            y_test.append(y[index])  # Add corresponding label to test set\n",
    "        \n",
    "        index = np.where(y == file_name[0])[0][0]  # Get index of the label in original labels\n",
    "        X_train.append(X[index])  # Add corresponding features to train set\n",
    "        y_train.append(y[index])  # Add corresponding label to train set\n",
    "\n",
    "# Convert lists back to numpy arrays\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Print shapes to confirm split\n",
    "print(f\"Training Features shape: {X_train.shape}, Training Labels shape: {y_train.shape}\")\n",
    "print(f\"Testing Features shape: {X_test.shape}, Testing Labels shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model and testing it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 100.00%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         1\n",
      "           A       1.00      1.00      1.00         1\n",
      "           B       1.00      1.00      1.00         1\n",
      "           C       1.00      1.00      1.00         1\n",
      "           H       1.00      1.00      1.00         1\n",
      "           X       1.00      1.00      1.00         1\n",
      "           Y       1.00      1.00      1.00         1\n",
      "           Z       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         9\n",
      "   macro avg       1.00      1.00      1.00         9\n",
      "weighted avg       1.00      1.00      1.00         9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize the SVM classifier\n",
    "classifier = SVC(kernel='linear')\n",
    "\n",
    "# Train the classifier on the training data\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Get unique labels from the test data for classification report\n",
    "target_names = np.unique(y_test)\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(y_test, y_pred, target_names=target_names)\n",
    "\n",
    "# Print results\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 100.00%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         1\n",
      "           A       1.00      1.00      1.00         1\n",
      "           B       1.00      1.00      1.00         1\n",
      "           C       1.00      1.00      1.00         1\n",
      "           H       1.00      1.00      1.00         1\n",
      "           X       1.00      1.00      1.00         1\n",
      "           Y       1.00      1.00      1.00         1\n",
      "           Z       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         9\n",
      "   macro avg       1.00      1.00      1.00         9\n",
      "weighted avg       1.00      1.00      1.00         9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 22.22%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       0.50      1.00      0.67         1\n",
      "           2       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           A       0.00      0.00      0.00         1\n",
      "           B       0.00      0.00      0.00         1\n",
      "           C       0.00      0.00      0.00         1\n",
      "           H       0.00      0.00      0.00         1\n",
      "           X       0.00      0.00      0.00         1\n",
      "           Y       0.00      0.00      0.00         1\n",
      "           Z       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.22         9\n",
      "   macro avg       0.12      0.15      0.13         9\n",
      "weighted avg       0.17      0.22      0.19         9\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hanon Systems\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Hanon Systems\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Hanon Systems\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Hanon Systems\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Hanon Systems\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Hanon Systems\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Initialize the KNN classifier\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)  # You can adjust n_neighbors based on your needs\n",
    "\n",
    "# Train the classifier on the training data\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = knn_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Model Accuracy: 100.00%\n",
      "Decision Tree Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         1\n",
      "           A       1.00      1.00      1.00         1\n",
      "           B       1.00      1.00      1.00         1\n",
      "           C       1.00      1.00      1.00         1\n",
      "           H       1.00      1.00      1.00         1\n",
      "           X       1.00      1.00      1.00         1\n",
      "           Y       1.00      1.00      1.00         1\n",
      "           Z       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         9\n",
      "   macro avg       1.00      1.00      1.00         9\n",
      "weighted avg       1.00      1.00      1.00         9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize the Decision Tree classifier\n",
    "dt_classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Train the classifier on the training data\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_dt = dt_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "\n",
    "# Generate classification report\n",
    "report_dt = classification_report(y_test, y_pred_dt)\n",
    "\n",
    "# Print results\n",
    "print(f\"Decision Tree Model Accuracy: {accuracy_dt * 100:.2f}%\")\n",
    "print(\"Decision Tree Classification Report:\")\n",
    "print(report_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Model Accuracy: 100.00%\n",
      "Decision Tree Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         1\n",
      "           A       1.00      1.00      1.00         1\n",
      "           B       1.00      1.00      1.00         1\n",
      "           C       1.00      1.00      1.00         1\n",
      "           H       1.00      1.00      1.00         1\n",
      "           X       1.00      1.00      1.00         1\n",
      "           Y       1.00      1.00      1.00         1\n",
      "           Z       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         9\n",
      "   macro avg       1.00      1.00      1.00         9\n",
      "weighted avg       1.00      1.00      1.00         9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize the Decision Tree classifier\n",
    "dt_classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Train the classifier on the training data\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_dt = dt_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "\n",
    "# Generate classification report\n",
    "report_dt = classification_report(y_test, y_pred_dt)\n",
    "\n",
    "# Print results\n",
    "print(f\"Decision Tree Model Accuracy: {accuracy_dt * 100:.2f}%\")\n",
    "print(\"Decision Tree Classification Report:\")\n",
    "print(report_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Model Accuracy: 100.00%\n",
      "Gradient Boosting Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         1\n",
      "           A       1.00      1.00      1.00         1\n",
      "           B       1.00      1.00      1.00         1\n",
      "           C       1.00      1.00      1.00         1\n",
      "           H       1.00      1.00      1.00         1\n",
      "           X       1.00      1.00      1.00         1\n",
      "           Y       1.00      1.00      1.00         1\n",
      "           Z       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         9\n",
      "   macro avg       1.00      1.00      1.00         9\n",
      "weighted avg       1.00      1.00      1.00         9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Initialize the Gradient Boosting classifier\n",
    "gb_classifier = GradientBoostingClassifier()\n",
    "\n",
    "# Train the classifier on the training data\n",
    "gb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_gb = gb_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_gb = accuracy_score(y_test, y_pred_gb)\n",
    "\n",
    "# Generate classification report\n",
    "report_gb = classification_report(y_test, y_pred_gb)\n",
    "\n",
    "# Print results\n",
    "print(f\"Gradient Boosting Model Accuracy: {accuracy_gb * 100:.2f}%\")\n",
    "print(\"Gradient Boosting Classification Report:\")\n",
    "print(report_gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Model Accuracy: 100.00%\n",
      "Naive Bayes Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         1\n",
      "           A       1.00      1.00      1.00         1\n",
      "           B       1.00      1.00      1.00         1\n",
      "           C       1.00      1.00      1.00         1\n",
      "           H       1.00      1.00      1.00         1\n",
      "           X       1.00      1.00      1.00         1\n",
      "           Y       1.00      1.00      1.00         1\n",
      "           Z       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         9\n",
      "   macro avg       1.00      1.00      1.00         9\n",
      "weighted avg       1.00      1.00      1.00         9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Initialize the Naive Bayes classifier\n",
    "nb_classifier = GaussianNB()\n",
    "\n",
    "# Train the classifier on the training data\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_nb = nb_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
    "\n",
    "# Generate classification report\n",
    "report_nb = classification_report(y_test, y_pred_nb)\n",
    "\n",
    "# Print results\n",
    "print(f\"Naive Bayes Model Accuracy: {accuracy_nb * 100:.2f}%\")\n",
    "print(\"Naive Bayes Classification Report:\")\n",
    "print(report_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Data on Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: ['H']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 74\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m     73\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./morse_code_testing/HI.wav\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Replace with the actual file path\u001b[39;00m\n\u001b[1;32m---> 74\u001b[0m predicted_word \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_word_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_encoder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted Word: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredicted_word\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[32], line 65\u001b[0m, in \u001b[0;36mprocess_word_audio\u001b[1;34m(file_path, classifier, label_encoder)\u001b[0m\n\u001b[0;32m     62\u001b[0m features \u001b[38;5;241m=\u001b[39m extract_features_from_segments(segments, sr)\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Step 5: Predict the letters using the SVM classifier\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m predicted_letters \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_svm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_encoder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# Step 6: Combine the predicted letters into a word\u001b[39;00m\n\u001b[0;32m     68\u001b[0m predicted_word \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(predicted_letters)\n",
      "Cell \u001b[1;32mIn[32], line 16\u001b[0m, in \u001b[0;36mpredict_svm\u001b[1;34m(features, classifier, label_encoder)\u001b[0m\n\u001b[0;32m     13\u001b[0m predictions \u001b[38;5;241m=\u001b[39m classifier\u001b[38;5;241m.\u001b[39mpredict(features)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Decode the predictions to actual letter labels\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m predicted_letters \u001b[38;5;241m=\u001b[39m \u001b[43mlabel_encoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predicted_letters\n",
      "File \u001b[1;32mc:\\Users\\Hanon Systems\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:162\u001b[0m, in \u001b[0;36mLabelEncoder.inverse_transform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    160\u001b[0m diff \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msetdiff1d(y, np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_)))\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(diff):\n\u001b[1;32m--> 162\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my contains previously unseen labels: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(diff))\n\u001b[0;32m    163\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(y)\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_[y]\n",
      "\u001b[1;31mValueError\u001b[0m: y contains previously unseen labels: ['H']"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "# Train the classifier\n",
    "classifier = SVC(kernel='linear')\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Function to predict letters using SVM\n",
    "def predict_svm(features, classifier, label_encoder):\n",
    "    # Predict using the trained classifier\n",
    "    predictions = classifier.predict(features)\n",
    "    \n",
    "    # Decode the predictions to actual letter labels\n",
    "    predicted_letters = label_encoder.inverse_transform(predictions)\n",
    "    \n",
    "    return predicted_letters\n",
    "\n",
    "# Load and preprocess the audio file (user input)\n",
    "def load_audio(file_path):\n",
    "    audio, sample_rate = librosa.load(file_path)\n",
    "    return audio, sample_rate\n",
    "\n",
    "# Detect pauses based on silence (using RMS method)\n",
    "def detect_pauses(audio, sample_rate, threshold=0.01):\n",
    "    rms = librosa.feature.rms(y=audio)[0]\n",
    "    pauses = np.where(rms < threshold)[0]\n",
    "    return pauses\n",
    "\n",
    "# Split the audio into segments by detected pauses\n",
    "def split_audio_by_pauses(audio, sample_rate, pauses, min_segment_duration=0.2):\n",
    "    segments = []\n",
    "    start = 0\n",
    "    for pause in pauses:\n",
    "        end = pause * (512 / sample_rate)  # Convert pause index to time\n",
    "        if end - start >= min_segment_duration:  # Ensure we only take longer segments\n",
    "            segments.append(audio[int(start * sample_rate):int(end * sample_rate)])\n",
    "        start = end\n",
    "    return segments\n",
    "\n",
    "# Extract MFCC features from each audio segment\n",
    "def extract_features_from_segments(segments, sample_rate):\n",
    "    features = []\n",
    "    for segment in segments:\n",
    "        mfccs = librosa.feature.mfcc(y=segment, sr=sample_rate, n_mfcc=40)\n",
    "        features.append(np.mean(mfccs.T, axis=0))  # Take mean across MFCCs\n",
    "    return np.array(features)\n",
    "\n",
    "# Main function to handle the entire flow\n",
    "def process_word_audio(file_path, classifier, label_encoder):\n",
    "    # Step 1: Load the audio file\n",
    "    audio, sr = load_audio(file_path)\n",
    "\n",
    "    # Step 2: Detect pauses in the audio\n",
    "    pauses = detect_pauses(audio, sr)\n",
    "\n",
    "    # Step 3: Split the audio into segments based on the pauses\n",
    "    segments = split_audio_by_pauses(audio, sr, pauses)\n",
    "\n",
    "    # Step 4: Extract MFCC features from each audio segment\n",
    "    features = extract_features_from_segments(segments, sr)\n",
    "\n",
    "    # Step 5: Predict the letters using the SVM classifier\n",
    "    predicted_letters = predict_svm(features, classifier, label_encoder)\n",
    "\n",
    "    # Step 6: Combine the predicted letters into a word\n",
    "    predicted_word = ''.join(predicted_letters)\n",
    "\n",
    "    return predicted_word\n",
    "\n",
    "# Example usage\n",
    "file_path = './morse_code_testing/HI.wav'  # Replace with the actual file path\n",
    "predicted_word = process_word_audio(file_path, classifier, label_encoder)\n",
    "print(f\"Predicted Word: {predicted_word}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
